{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framework and Sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I focus on situations in which interest lies in estimating a $K\\times1$\n",
    "vector of parameters, $\\theta$, given some $L\\times1$ vector of\n",
    "calibrated parameters, $\\hat{\\gamma}$. \n",
    "Interest may then be in using\n",
    "these estimates to subsequently analyze different model outcomes and\n",
    "predictions. \n",
    "\n",
    "I assume that the estimation approach employed is of the form\n",
    "$$\n",
    "\\hat{\\theta}=\\arg\\min_{\\theta\\in\\Theta}g_{n}(\\theta|\\hat{\\gamma})'W_{n}g_{n}(\\theta|\\hat{\\gamma})\n",
    "$$\n",
    "where $W_{n}$ is a $J\\times J$ positive semi-definite weighting matrix and $$g_{n}(\\theta|\\hat{\\gamma})=\\frac{1}{n}\\sum_{i=1}^{n}f(\\theta|\\hat{\\gamma},\\mathbf{w}_{i})$$\n",
    "is some $J\\times1$ vector valued function of the parameters and data,\n",
    "$\\mathbf{w}_{i}$ for $i=1,\\dots,n$, specified by the researcher.\n",
    "\n",
    "When estimating dynamic economic models, evaluating $g_{n}(\\theta|\\hat{\\gamma})$\n",
    "typically involves solving some model numerically. Evaluating $g_{n}(\\bullet)$ might thus be computationally costly to evaluate.\n",
    "\n",
    "I assume that the\n",
    "objective function satisfies standard regularity conditions. In particular,\n",
    "I assume that there exists unique population parameters $\\theta_{0}$\n",
    "and $\\gamma_{0}$ such that $g(\\theta_{0}|\\gamma_{0})\\equiv\\mathbb{E}\\left[f(\\theta_{0}|\\gamma_{0},\\mathbf{w}_{i})\\right]=0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Measure\n",
    "\n",
    "I propose a systematic sensitivity measure that can be calculated\n",
    "without significant additional computational cost. The interpretation\n",
    "of the measure is an approximation of the change in $\\theta$ from\n",
    "a marginal change in the calibrated parameters. The main sensitivity\n",
    "measure is local but I also discuss an alternative approach that can\n",
    "in principle be used to emulate the current practice discussed above\n",
    "without the computational burden of re-estimating the model for various\n",
    "$\\tilde{\\gamma}$.\n",
    "\n",
    "The sensitivity measure is motivated by a standard representation\n",
    "used in asymptotic derivations. In particular, I use that estimators\n",
    "within the current framework has an asymptotic linear form \\citep{NeweyMcFadden1994},\n",
    "such that the estimator can be represented as\n",
    "\\begin{equation}\n",
    "\\hat{\\theta}(\\hat{\\gamma})=\\theta_{0}+\\Lambda_{n}(\\hat{\\gamma})g_{n}(\\theta_{0}|\\hat{\\gamma})+o_{p}(n^{-\\frac{1}{2}})\\label{eq:asym linear}\n",
    "\\end{equation}\n",
    "where $\\Lambda_{n}(\\hat{\\gamma})=-(G_{n}'W_{n}G_{n})^{-1}G_{n}'W_{n}$\n",
    "and $G_{n}=\\left.\\frac{\\partial g_{n}(\\theta|\\hat{\\gamma})}{\\partial\\theta'}\\right|_{\\theta=\\theta_{0}}$\n",
    "is the $J\\times K$ Jacobian w.r.t. the estimated parameters. Although\n",
    "suppressed in the notation here, $G_{n}$ depends on the calibrated\n",
    "parameters, $\\hat{\\gamma}$. Under fairly standard regularity conditions,\n",
    "similar in spirit to those employed in e.g. \\citet{NeweyMcFadden1994}\n",
    "and \\citet{AndrewsGentzkowShapiro2017_sensitivity}, the estimator\n",
    "converges in probability to\n",
    "\\begin{equation}\n",
    "\\theta(\\gamma)=\\theta_{0}+\\Lambda(\\gamma)g(\\theta_{0}|\\gamma)\\label{eq:plim}\n",
    "\\end{equation}\n",
    "where $g(\\theta_{0}|\\gamma)\\equiv\\mathbb{E}\\left[f(\\theta_{0}|\\gamma,\\mathbf{w}_{i})\\right]$,\n",
    "$\\Lambda(\\gamma)=-(G'WG)^{-1}G'W$ with $G=\\mathbb{E}\\left[\\left.\\frac{\\partial f(\\theta|\\gamma,\\mathbf{w}_{i})}{\\partial\\theta'}\\right|_{\\theta=\\theta_{0}}\\right]$\n",
    "and $\\gamma\\equiv\\text{plim}_{n\\rightarrow\\infty}\\hat{\\gamma}$ is\n",
    "the probability limit of the calibrated parameters. This setup e.g.\n",
    "allows for cases in which $\\gamma\\neq\\gamma_{0}$ and thus $g(\\theta_{0}|\\gamma)\\neq0$.\n",
    "$\\hat{\\theta}$ is a consistent estimator if $g(\\theta_{0}|\\gamma)=0$,\n",
    "which is the case if the calibrated parameters are consistent estimators\n",
    "of the population values, $\\text{plim}_{n\\rightarrow\\infty}\\hat{\\gamma}=\\gamma_{0}$,\n",
    "or simply assumed fixed at their population values, $\\hat{\\gamma}=\\gamma_{0}$.\n",
    "\n",
    "Motivated by this formulation, I propose the sensitivity measure $\\frac{\\partial\\theta}{\\partial\\gamma'}=(\\frac{\\partial\\theta}{\\partial\\gamma_{(1)}},\\dots,\\frac{\\partial\\theta}{\\partial\\gamma_{(L)}})$.\n",
    "This is a $K\\times L$ Jacobian matrix with the derivative of $\\theta(\\gamma)$\n",
    "with respect to the $l$th element in $\\gamma$ being a $K\\times1$\n",
    "vector\n",
    "\\begin{equation}\n",
    "\\frac{\\partial\\theta}{\\partial\\gamma_{(l)}}=\\frac{\\partial\\Lambda(\\gamma)}{\\partial\\gamma_{(l)}}g(\\theta_{0}|\\gamma)+\\Lambda(\\gamma)\\frac{\\partial g(\\theta_{0}|\\gamma)}{\\partial\\gamma_{(l)}}\\label{eq:dtheta/dgamma_l}\n",
    "\\end{equation}\n",
    "with\n",
    "\\begin{align*}\n",
    "\\frac{\\partial\\Lambda(\\gamma)}{\\partial\\gamma_{(l)}} & =-(G'WG)^{-1}[\\nabla_{l}'WG+G'W\\nabla_{l}](G'WG)^{-1}G'W+(G'WG)^{-1}\\nabla_{l}'W\\\\\n",
    " & =-\\Lambda\\nabla_{l}\\Lambda+(G'WG)^{-1}\\nabla_{l}'W(I_{J\\times J}+G\\Lambda)\n",
    "\\end{align*}\n",
    "being a $K\\times J$ matrix where $\\nabla_{l}\\equiv\\frac{\\partial G}{\\partial\\gamma_{(l)}}=\\mathbb{E}\\left[\\left.\\frac{\\partial^{2}f(\\theta|\\gamma,\\mathbf{w}_{i})}{\\partial\\gamma_{(l)}\\partial\\theta'}\\right|_{\\theta=\\theta_{0}}\\right]$\n",
    "is a $J\\times K$ Jacobian. \n",
    "\n",
    "The sensitivity measure can be calculated using eq. (\\ref{eq:dtheta/dgamma_l})\n",
    "above in principle without placing restrictions on the value of $\\hat{\\gamma}$.\n",
    "Since the asymptotic linear representation is an approximation around\n",
    "the true parameter, $\\theta_{0}$, the approximation is most accurate\n",
    "close to $\\theta_{0}$. The approximation might thus be less accurate\n",
    "for values of $\\hat{\\gamma}$ far from $\\gamma_{0}$. Under the frequently\n",
    "employed assumption that $\\gamma=\\gamma_{0}$, such that $g(\\theta_{0}|\\gamma)=g(\\theta_{0}|\\gamma_{0})=0$,\n",
    "the measure simplifies considerably.\\footnote{The measure $S$ in equation (\\ref{eq:plim}) is similar to that derived\n",
    "in \\citet{NeweyMcFadden1994} but with the weight $W$ included here.\n",
    "\\citet{NeweyMcFadden1994} suggests this measure to determine if the\n",
    "asymptotic variance of a two-step estimator should be corrected for\n",
    "the uncertainty associated with the first-step estimator.}\n",
    "\\begin{defn}\n",
    "[Sensitivity of estimated parameters] Under the assumption that $g(\\theta_{0}|\\gamma)=0$,\n",
    "such that $\\hat{\\theta}$ is a consistent estimator of $\\theta_{0}$,\n",
    "the sensitivity of the estimated parameters to the calibrated parameters\n",
    "is the $K\\times L$ matrix\n",
    "\\begin{equation}\n",
    "S=\\Lambda D\\label{eq:Sens}\n",
    "\\end{equation}\n",
    "where $D=\\mathbb{E}\\left[\\frac{\\partial f(\\theta_{0}|\\gamma,\\mathbf{w}_{i})}{\\partial\\gamma'}\\right]$\n",
    "is a $J\\times L$ Jacobian w.r.t. the calibrated parameters.\\vspace{3mm}\\label{prop:sens}\n",
    "\\end{defn}\n",
    "The sensitivity measure can be estimated at low cost by plugging in\n",
    "estimates of $\\hat{\\theta}$ and $\\hat{\\gamma}$ as\n",
    "\\begin{equation}\n",
    "\\hat{S}_{n}=\\hat{\\Lambda}_{n}\\hat{D}_{n}.\\label{eq:Sens_n}\n",
    "\\end{equation}\n",
    "where $\\hat{\\Lambda}_{n}=-(\\hat{G}_{n}'W_{n}\\hat{G}_{n})^{-1}\\hat{G}_{n}'W_{n}$\n",
    "with $\\hat{G}_{n}=\\left.\\frac{\\partial g_{n}(\\theta|\\hat{\\gamma})}{\\partial\\theta'}\\right|_{\\theta=\\hat{\\theta}}$\n",
    "and $\\hat{D}_{n}=\\frac{\\partial g_{n}(\\hat{\\theta}|\\hat{\\gamma})}{\\partial\\hat{\\gamma}'}$.\n",
    "Importantly, all elements of $\\hat{\\Lambda}_{n}$ are already constructed\n",
    "when calculating the asymptotic covariance matrix of $\\hat{\\theta}$\n",
    "and only $\\hat{D}_{n}$ needs to be calculated.\\footnote{In fact, if asymptotic standard errors are corrected for the two-step\n",
    "estimation approach, as in \\citet{GourinchasParker2002}, all elements\n",
    "of the sensitivity measure is already calculated.} For example, if forward finite differences are used to construct\n",
    "$\\hat{D}_{n}$ numerically, calculating $\\hat{S}_{n}$ only requires\n",
    "$L=\\dim(\\gamma)$ additional evaluations of the objective function.\n",
    "A brute force alternative approach to calculating $\\frac{\\partial\\theta}{\\partial\\gamma'}$\n",
    "could be to re-estimate $\\theta$ for a small increase in each element\n",
    "in $\\gamma$ and calculate the change in the estimated $\\theta$.\n",
    "This approach , however, requires $L$ \\emph{re-estimations} of the\n",
    "model. The brute force approach is thus generally much more time consuming.\n",
    "In the main application below, I compare the proposed sensitivity\n",
    "measure to such a brute-force approach and find only minor differences. \n",
    "\n",
    "The sensitivity measure has a straightforward interpretation and the\n",
    "elasticity of the $k$th estimated parameter to the $l$th calibrated\n",
    "parameter can be calculated as\n",
    "\\begin{equation}\n",
    "\\mathcal{E}_{(k,l)}=S_{(k,l)}\\gamma_{(l)}/\\theta_{(k)}\\label{eq:Sens elasticity}\n",
    "\\end{equation}\n",
    "assuming that $\\gamma_{(l)},\\theta_{(k)}\\neq0$. \n",
    "\\begin{example*}\n",
    "[Linear Regression] Consider a simple linear regression model with\n",
    "two mean-zero explanatory variables, $X_{1}$ and $X_{2}$, and measurement\n",
    "error, $\\varepsilon$,\n",
    "\\[\n",
    "Y_{i}=\\beta_{1}X_{1,i}+\\beta_{2}X_{2,i}+\\varepsilon_{i}\n",
    "\\]\n",
    "where $\\mathbb{E}[\\varepsilon|X_{1},X_{2}]=0$ is the identifying\n",
    "assumption. Imagine fixing the second parameter to $\\beta_{2}$ and\n",
    "only estimating $\\beta_{1}$,\n",
    "\\[\n",
    "\\hat{\\beta}_{1}=\\arg\\min_{\\beta_{1}}g_{n}(\\beta_{1}|\\beta_{2})^{2}\n",
    "\\]\n",
    "with a single moment in $g_{n}(\\beta_{1}|\\beta_{2})=\\frac{1}{n}\\sum_{i=1}^{n}(Y_{i}-\\beta_{1}X_{1,i}-\\beta_{2}X_{2,i})X_{1,i}$\n",
    "and $W=1$. This estimator can be found in closed form as \n",
    "\\begin{equation}\n",
    "\\hat{\\beta}_{1}=\\frac{\\sum_{i=1}^{n}X_{1,i}(Y_{i}-\\beta_{2}X_{2,i})}{\\sum_{i=1}^{n}X_{1,i}^{2}}.\\label{eq:Ex1 OLS}\n",
    "\\end{equation}\n",
    "In this setting $G_{n}=-\\sum_{i=1}^{n}X_{1,i}^{2}$ and $D_{n}=-\\sum_{i=1}^{n}X_{1,i}X_{2,i}$\n",
    "and the sensitivity measure is\n",
    "\\[\n",
    "S_{n}=-\\frac{\\sum_{i=1}^{n}X_{1,i}X_{2,i}}{\\sum_{i=1}^{n}X_{1,i}^{2}}\n",
    "\\]\n",
    "which converges in probability to $-\\mathbb{E}[X_{1}X_{2}]\\cdot\\mathbb{E}[X_{2}^{2}]^{-1}$.\n",
    "This is the negated regression coefficient in a regression of $X_{2}$\n",
    "on $X_{1}$ with the sample covariance between $X_{1}$ and $X_{2}$\n",
    "in the nominator. We see the intuitive result that if they are positively\n",
    "(negatively) correlated, increasing $\\beta_{2}$ would lead to a reduced\n",
    "(increased) $\\hat{\\beta}_{1}$. We also see that if they are uncorrelated,\n",
    "the estimator of $\\beta_{1}$ is completely insensitive to $\\beta_{2}$.\n",
    "\n",
    "Because the linear asymptotic representation is exact in this example,\n",
    "$S_{n}=\\frac{\\partial\\hat{\\beta}_{1}}{\\partial\\beta_{2}}$. In general,\n",
    "however, such a direct derivative cannot be calculated in closed form\n",
    "and I thus propose to use the approximation instead.\n",
    "\\end{example*}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}